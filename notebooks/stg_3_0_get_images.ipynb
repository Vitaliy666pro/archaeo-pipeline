{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-29 19:49:23,606 INFO Found 24 entries across 8 prefixes (max 3 each)\n",
      "2025-06-29 19:49:23,607 INFO Processing tile HUM_A01_2013_laz_11\n",
      "/tmp/ipykernel_3367/4129789823.py:134: RuntimeWarning: invalid value encountered in cast\n",
      "  return (np.clip(hs, 0, 1) * 255).astype(\"uint8\")\n",
      "2025-06-29 19:49:33,984 INFO Processing tile HUM_A01_2013_laz_10\n",
      "2025-06-29 19:49:44,101 INFO Processing tile HUM_A01_2018_LAS_8\n",
      "2025-06-29 19:49:54,156 INFO Processing tile BON_A01_2018_LAS_11\n",
      "2025-06-29 19:50:04,328 INFO Processing tile BON_A01_2018_LAS_0\n",
      "2025-06-29 19:50:14,660 INFO Processing tile BON_A01_2018_LAS_5\n",
      "2025-06-29 19:50:24,238 INFO Processing tile RIB_A01_2018_LAS_5\n",
      "2025-06-29 19:50:34,122 INFO Processing tile RIB_A01_2014_laz_3\n",
      "2025-06-29 19:50:43,976 INFO Processing tile RIB_A01_2018_LAS_12\n",
      "2025-06-29 19:50:53,632 INFO Processing tile TAL_A01_2018_LAS_6\n",
      "2025-06-29 19:51:03,097 INFO Processing tile TAL_A01_2018_LAS_8\n",
      "2025-06-29 19:51:11,710 INFO Processing tile TAL_A01_2018_LAS_2\n",
      "2025-06-29 19:51:21,101 INFO Processing tile TAP_A02_2018_LAS_7\n",
      "2025-06-29 19:51:30,543 INFO Processing tile TAP_A02_2013_laz_2\n",
      "2025-06-29 19:51:39,865 INFO Processing tile TAP_A02_2012_laz_2\n",
      "2025-06-29 19:51:49,265 INFO Processing tile TAP_A03_2018_LAS_0\n",
      "2025-06-29 19:51:58,561 INFO Processing tile TAP_A03_2018_LAS_11\n",
      "2025-06-29 19:52:07,531 INFO Processing tile TAP_A03_2016_laz_10\n",
      "2025-06-29 19:52:16,310 INFO Processing tile TAP_A06_2018_LAS_2\n",
      "2025-06-29 19:52:25,149 INFO Processing tile TAP_A06_2018_LAS_0\n",
      "2025-06-29 19:52:33,500 INFO Processing tile TAP_A06_2008_laz_0\n",
      "2025-06-29 19:52:42,213 INFO Processing tile PRG_A01_2013_P08a_laz_4\n",
      "2025-06-29 19:52:51,343 INFO Processing tile PRG_A01_2013_P08b_laz_9\n",
      "2025-06-29 19:53:00,406 INFO Processing tile PRG_A01_2013_P08b_laz_5\n",
      "2025-06-29 19:53:09,093 INFO Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import ee\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from ee import ServiceAccountCredentials\n",
    "\n",
    "# ─────────────────────────── Load environment variables ───────────────────────────\n",
    "load_dotenv()\n",
    "\n",
    "# ─────────────────────────── Load configuration from config.yaml ───────────────────────────\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "RAW_DATA_DIR = Path(config[\"raw_data_dir\"])\n",
    "RESULTS_DIR  = Path(config[\"results_dir\"])\n",
    "\n",
    "# Directory containing the LiDAR DTM tiles\n",
    "DTM_DIR = (\n",
    "    RAW_DATA_DIR\n",
    "    / \"datasets\"\n",
    "    / \"nasa-amazon-lidar-2008-2018\"\n",
    "    / \"Nasa_lidar_2008_to_2018_DTMs\"\n",
    "    / \"DTM_tiles\"\n",
    ")\n",
    "\n",
    "# CSV file listing the candidate tiles to process\n",
    "PATH_TO_COORDS_CSV = RESULTS_DIR / \"short_list.csv\"\n",
    "\n",
    "# Output directory for predicted results\n",
    "OUT_DIR = RESULTS_DIR / \"predicted\"\n",
    "# Create output directory if it doesn't exist\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ─────────────────────────── Earth Engine authentication ───────────────────────────\n",
    "GSA_EMAIL_VAR = os.getenv(\"GSA_EMAIL\")\n",
    "KEY_PATH_VAR  = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "\n",
    "creds = ServiceAccountCredentials(GSA_EMAIL_VAR, KEY_PATH_VAR)\n",
    "ee.Initialize(credentials=creds)\n",
    "\n",
    "# ─────────────────────────── Processing parameters ───────────────────────────\n",
    "MAX_PHOTOS_PER_PREFIX = 3       # Max entries per prefix\n",
    "BUFFER_RADIUS_METERS  = 1500    # Radius for buffering points (meters)\n",
    "DATE_TO_DOWNLOAD      = \"2025-05-01\"\n",
    "AZ1, ALT1             = 315, 45  # Azimuth and altitude for first hillshade\n",
    "AZ2, ALT2             = 45, 30   # Azimuth and altitude for second hillshade\n",
    "\n",
    "# Sentinel-1 and Sentinel-2 collection and visualization parameters\n",
    "EE_COLLECTION_S1 = \"COPERNICUS/S1_GRD\"\n",
    "VIS_PARAMS_S1    = {'bands': ['VV'], 'min': -25, 'max': 5}\n",
    "EE_COLLECTION_S2 = \"COPERNICUS/S2_SR_HARMONIZED\"\n",
    "VIS_PARAMS_S2    = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000, 'gamma': 1.3}\n",
    "\n",
    "# Ensure the CSV exists\n",
    "if not PATH_TO_COORDS_CSV.exists():\n",
    "    raise FileNotFoundError(f\"CSV not found: {PATH_TO_COORDS_CSV}\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "\n",
    "# ─────────────────────────── Helper functions ───────────────────────────\n",
    "def get_best_s1(pt, start, end):\n",
    "    \"\"\"\n",
    "    Fetch the earliest Sentinel-1 image in the given date range for the point.\n",
    "    Returns the image and its bounding geometry.\n",
    "    \"\"\"\n",
    "    geom = ee.Geometry.Point(pt).buffer(BUFFER_RADIUS_METERS).bounds()\n",
    "    img  = (\n",
    "        ee.ImageCollection(EE_COLLECTION_S1)\n",
    "        .filterBounds(ee.Geometry.Point(pt))\n",
    "        .filterDate(start, end)\n",
    "        .sort('system:time_start')\n",
    "        .first()\n",
    "    )\n",
    "    return img, geom\n",
    "\n",
    "def get_best_s2(pt, start, end, max_cloud=30):\n",
    "    \"\"\"\n",
    "    Fetch the least cloudy Sentinel-2 image in the given date range for the point.\n",
    "    Returns the image and its bounding geometry.\n",
    "    \"\"\"\n",
    "    geom = ee.Geometry.Point(pt).buffer(BUFFER_RADIUS_METERS).bounds()\n",
    "    img  = (\n",
    "        ee.ImageCollection(EE_COLLECTION_S2)\n",
    "        .filterBounds(ee.Geometry.Point(pt))\n",
    "        .filterDate(start, end)\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud))\n",
    "        .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    "        .first()\n",
    "    )\n",
    "    return img, geom\n",
    "\n",
    "def save_jpg(img, region, out_path, vis_params):\n",
    "    \"\"\"\n",
    "    Save a visualized Earth Engine image as JPEG.\n",
    "    \"\"\"\n",
    "    vis = img.visualize(**vis_params)\n",
    "    url = vis.getThumbURL({'region': region, 'dimensions': 800, 'format': 'jpg'})\n",
    "    data = urllib.request.urlopen(url).read()\n",
    "    out_path.write_bytes(data)\n",
    "\n",
    "def save_tif(img, region, out_path, bands=None):\n",
    "    \"\"\"\n",
    "    Save an Earth Engine image as GeoTIFF.\n",
    "    \"\"\"\n",
    "    params = {'scale': 10, 'region': region, 'format': 'GEO_TIFF', 'crs': 'EPSG:4326'}\n",
    "    if bands:\n",
    "        params['bands'] = bands\n",
    "    url  = img.getDownloadURL(params)\n",
    "    data = urllib.request.urlopen(url).read()\n",
    "    out_path.write_bytes(data)\n",
    "\n",
    "def hillshade(arr, az, alt):\n",
    "    \"\"\"\n",
    "    Compute hillshade from a single-band array given sun azimuth and altitude.\n",
    "    \"\"\"\n",
    "    az, alt = np.deg2rad([az, alt])\n",
    "    dy, dx  = np.gradient(arr.astype(\"float32\"), edge_order=2)\n",
    "    slope   = np.arctan(np.hypot(dx, dy))\n",
    "    aspect  = np.arctan2(dy, -dx)\n",
    "    hs = (np.sin(alt) * np.cos(slope) +\n",
    "          np.cos(alt) * np.sin(slope) * np.cos(az - aspect))\n",
    "    return (np.clip(hs, 0, 1) * 255).astype(\"uint8\")\n",
    "\n",
    "# ─────────────────────────── Main processing ───────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # Clear the output directory before running\n",
    "    if OUT_DIR.exists():\n",
    "        shutil.rmtree(OUT_DIR)\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    matches = []\n",
    "    prefix_counts = {}\n",
    "\n",
    "    # Read candidate tiles from CSV and limit by prefix\n",
    "    with open(PATH_TO_COORDS_CSV, newline='', encoding='utf-8') as cf:\n",
    "        reader = csv.DictReader(cf)\n",
    "        for row in reader:\n",
    "            full_stem = Path(row[\"filename\"]).stem\n",
    "            prefix    = \"_\".join(full_stem.split(\"_\")[:2])\n",
    "            cnt       = prefix_counts.get(prefix, 0)\n",
    "            if cnt >= MAX_PHOTOS_PER_PREFIX:\n",
    "                continue\n",
    "            prefix_counts[prefix] = cnt + 1\n",
    "\n",
    "            # Compute center coordinates of the tile\n",
    "            minx, miny = float(row[\"min_lon\"]), float(row[\"min_lat\"])\n",
    "            maxx, maxy = float(row[\"max_lon\"]), float(row[\"max_lat\"])\n",
    "            center     = [(minx + maxx) / 2, (miny + maxy) / 2]\n",
    "            matches.append((full_stem, center))\n",
    "\n",
    "    logging.info(\n",
    "        f\"Found {len(matches)} entries across {len(prefix_counts)} prefixes (max {MAX_PHOTOS_PER_PREFIX} each)\"\n",
    "    )\n",
    "\n",
    "    # Process each tile\n",
    "    for stem, pt in matches:\n",
    "        logging.info(f\"Processing tile {stem}\")\n",
    "        tile_dir = OUT_DIR / stem\n",
    "        tile_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Copy LiDAR DTM file\n",
    "        lidar_fp = DTM_DIR / f\"{stem}.tif\"\n",
    "        if not lidar_fp.exists():\n",
    "            logging.warning(f\"LiDAR TIFF missing for {stem}\")\n",
    "            continue\n",
    "        shutil.copy(lidar_fp, tile_dir / f\"{stem}_lidar.tif\")\n",
    "\n",
    "        # Define date range and region for Earth Engine\n",
    "        start  = \"2024-01-01\"\n",
    "        end    = f\"{DATE_TO_DOWNLOAD}T23:59:59\"\n",
    "        region = ee.Geometry.Point(pt).buffer(BUFFER_RADIUS_METERS).bounds()\n",
    "\n",
    "        # Fetch and save Sentinel-1 imagery\n",
    "        s1_img, s1_reg = get_best_s1(pt, start, end)\n",
    "        if s1_img:\n",
    "            save_jpg(s1_img, s1_reg, tile_dir / f\"{stem}_S1_{DATE_TO_DOWNLOAD}.jpg\", VIS_PARAMS_S1)\n",
    "            save_tif(s1_img, s1_reg, tile_dir / f\"{stem}_S1_{DATE_TO_DOWNLOAD}.tif\")\n",
    "        else:\n",
    "            logging.warning(f\"No S1 imagery for {stem}\")\n",
    "\n",
    "        # Fetch and save Sentinel-2 imagery\n",
    "        s2_img, s2_reg = get_best_s2(pt, start, end)\n",
    "        if s2_img:\n",
    "            save_jpg(s2_img, s2_reg, tile_dir / f\"{stem}_S2_{DATE_TO_DOWNLOAD}.jpg\", VIS_PARAMS_S2)\n",
    "            save_tif(s2_img, s2_reg, tile_dir / f\"{stem}_S2_{DATE_TO_DOWNLOAD}.tif\", bands=['B4', 'B3', 'B2'])\n",
    "        else:\n",
    "            logging.warning(f\"No S2 imagery for {stem}\")\n",
    "\n",
    "        # Compute and save hillshade composite from LiDAR\n",
    "        with rasterio.open(lidar_fp) as src:\n",
    "            arr = src.read(1).astype(\"float32\")\n",
    "            nod = src.nodata\n",
    "            if nod is not None:\n",
    "                arr[arr == nod] = np.nan\n",
    "        hs1 = hillshade(arr, AZ1, ALT1)\n",
    "        hs2 = hillshade(arr, AZ2, ALT2)\n",
    "        comp = np.concatenate([hs1, hs2], axis=1)\n",
    "        Image.fromarray(comp).save(tile_dir / f\"{stem}_lidar_hillshade.jpg\", quality=90)\n",
    "\n",
    "    logging.info(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Archaeo-Pipeline)",
   "language": "python",
   "name": "archaeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
