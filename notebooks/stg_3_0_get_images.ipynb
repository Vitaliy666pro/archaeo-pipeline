{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GOOGLE_APPLICATION_CREDENTIALS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Другие параметры\u001b[39;00m\n\u001b[1;32m     37\u001b[0m GSA_email \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGSA_email\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m KEY_PATH \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGOOGLE_APPLICATION_CREDENTIALS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     40\u001b[0m MAX_PHOTOS_PER_PREFIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     41\u001b[0m BUFFER_RADIUS_METERS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/archaeo/lib/python3.9/os.py:679\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    676\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GOOGLE_APPLICATION_CREDENTIALS'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import ee\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from ee import ServiceAccountCredentials\n",
    "load_dotenv()\n",
    "# ─────────────────────────── Load config.yaml ───────────────────────────\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "RAW_DATA_DIR        = Path(config[\"raw_data_dir\"])\n",
    "PROCESSED_DATA_DIR  = Path(config[\"processed_data_dir\"])\n",
    "INTERIM_DATA_DIR    = Path(config[\"interim_data_dir\"])\n",
    "RESULTS_DIR         = Path(config[\"results_dir\"])\n",
    "EMBEDDING_DIR       = Path(config[\"embedding_parquet_dir\"])\n",
    "AOI_CRS             = config[\"aoi_crs\"]\n",
    "METRIC_CRS          = config[\"metric_crs\"]\n",
    "AOI_BOX             = config[\"aoi_box\"]\n",
    "\n",
    "# Обновлённые абсолютные пути\n",
    "DTM_DIR = RAW_DATA_DIR / \"datasets/nasa-amazon-lidar-2008-2018/Nasa_lidar_2008_to_2018_DTMs\"\n",
    "PATH_TO_COORDS_CSV = RAW_DATA_DIR / \"datasets/nasa-amazon-lidar-2008-2018/cms_brazil_lidar_tile_inventory.csv\"\n",
    "\n",
    "# Папка predicted внутри results/\n",
    "OUT_DIR = RESULTS_DIR / \"predicted\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Другие параметры\n",
    "GSA_email = os.getenv(\"GSA_email\")\n",
    "KEY_PATH = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]\n",
    "\n",
    "MAX_PHOTOS_PER_PREFIX = 3\n",
    "BUFFER_RADIUS_METERS = 1500\n",
    "DATE_TO_DOWNLOAD = \"2025-05-01\"\n",
    "AZ1, ALT1 = 315, 45\n",
    "AZ2, ALT2 = 45, 30\n",
    "\n",
    "EE_COLLECTION_S1 = \"COPERNICUS/S1_GRD\"\n",
    "VIS_PARAMS_S1 = {'bands': ['VV'], 'min': -25, 'max': 5}\n",
    "EE_COLLECTION_S2 = \"COPERNICUS/S2_SR_HARMONIZED\"\n",
    "VIS_PARAMS_S2 = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000, 'gamma': 1.3}\n",
    "\n",
    "if not PATH_TO_COORDS_CSV.exists():\n",
    "    raise FileNotFoundError(f\"CSV not found: {PATH_TO_COORDS_CSV}\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\"\n",
    ")\n",
    "\n",
    "creds = ServiceAccountCredentials(GSA_email, KEY_PATH)\n",
    "ee.Initialize(credentials=creds, project=\"kaggle-ai-to-z\")\n",
    "# ─────────────────────────── Helpers ────────────────────────────\n",
    "def get_best_s1(pt, start, end):\n",
    "    geom = ee.Geometry.Point(pt).buffer(BUFFER_RADIUS_METERS).bounds()\n",
    "    img = (ee.ImageCollection(EE_COLLECTION_S1)\n",
    "           .filterBounds(ee.Geometry.Point(pt))\n",
    "           .filterDate(start, end)\n",
    "           .sort('system:time_start')\n",
    "           .first())\n",
    "    return img, geom\n",
    "\n",
    "def get_best_s2(pt, start, end, max_cloud=30):\n",
    "    geom = ee.Geometry.Point(pt).buffer(BUFFER_RADIUS_METERS).bounds()\n",
    "    img = (ee.ImageCollection(EE_COLLECTION_S2)\n",
    "           .filterBounds(ee.Geometry.Point(pt))\n",
    "           .filterDate(start, end)\n",
    "           .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud))\n",
    "           .sort('CLOUDY_PIXEL_PERCENTAGE')\n",
    "           .first())\n",
    "    return img, geom\n",
    "\n",
    "def save_jpg(img, region, out_path, vis_params):\n",
    "    vis = img.visualize(**vis_params)\n",
    "    url = vis.getThumbURL({'region': region, 'dimensions': 800, 'format': 'jpg'})\n",
    "    data = urllib.request.urlopen(url).read()\n",
    "    out_path.write_bytes(data)\n",
    "\n",
    "def save_tif(img, region, out_path, bands=None):\n",
    "    params = {'scale': 10, 'region': region, 'format': 'GEO_TIFF', 'crs': 'EPSG:4326'}\n",
    "    if bands:\n",
    "        params['bands'] = bands\n",
    "    url = img.getDownloadURL(params)\n",
    "    data = urllib.request.urlopen(url).read()\n",
    "    out_path.write_bytes(data)\n",
    "\n",
    "def hillshade(arr, az, alt):\n",
    "    az, alt = np.deg2rad([az, alt])\n",
    "    dy, dx = np.gradient(arr.astype(\"float32\"), edge_order=2)\n",
    "    slope = np.arctan(np.hypot(dx, dy))\n",
    "    aspect = np.arctan2(dy, -dx)\n",
    "    hs = (np.sin(alt) * np.cos(slope) +\n",
    "          np.cos(alt) * np.sin(slope) * np.cos(az - aspect))\n",
    "    return (np.clip(hs, 0, 1) * 255).astype(\"uint8\")\n",
    "\n",
    "# ─────────────────────────── Main ────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    matches = []\n",
    "    prefix_counts = {}\n",
    "    with open(PATH_TO_COORDS_CSV, newline='', encoding='utf-8') as cf:\n",
    "        reader = csv.DictReader(cf)\n",
    "        for row in reader:\n",
    "            full_stem = Path(row[\"filename\"]).stem.replace(\".laz\", \"\")\n",
    "            prefix = \"_\".join(full_stem.split(\"_\")[:2])\n",
    "            cnt = prefix_counts.get(prefix, 0)\n",
    "            if cnt >= MAX_PHOTOS_PER_PREFIX:\n",
    "                continue\n",
    "            prefix_counts[prefix] = cnt + 1\n",
    "\n",
    "            minx, miny = float(row[\"min_lon\"]), float(row[\"min_lat\"])\n",
    "            maxx, maxy = float(row[\"max_lon\"]), float(row[\"max_lat\"])\n",
    "            center = [(minx + maxx) / 2, (miny + maxy) / 2]\n",
    "            matches.append((full_stem, center))\n",
    "\n",
    "    logging.info(\n",
    "        f\"Found {len(matches)} entries across \"\n",
    "        f\"{len(prefix_counts)} prefixes (max {MAX_PHOTOS_PER_PREFIX} each)\"\n",
    "    )\n",
    "\n",
    "    for stem, pt in matches:\n",
    "        logging.info(f\"Processing tile {stem}\")\n",
    "        tile_dir = OUT_DIR / stem\n",
    "        tile_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        lidar_fp = DTM_DIR / f\"{stem}.tif\"\n",
    "        if not lidar_fp.exists():\n",
    "            logging.warning(f\" LiDAR TIFF missing for {stem}\")\n",
    "            continue\n",
    "        shutil.copy(lidar_fp, tile_dir / f\"{stem}_lidar.tif\")\n",
    "\n",
    "        start = \"2024-01-01\"\n",
    "        end = f\"{DATE_TO_DOWNLOAD}T23:59:59\"\n",
    "        region = ee.Geometry.Point(pt).buffer(BUFFER_RADIUS_METERS).bounds()\n",
    "\n",
    "        s1_img, s1_reg = get_best_s1(pt, start, end)\n",
    "        if s1_img:\n",
    "            save_jpg(s1_img, s1_reg, tile_dir / f\"{stem}_S1_{DATE_TO_DOWNLOAD}.jpg\", VIS_PARAMS_S1)\n",
    "            save_tif(s1_img, s1_reg, tile_dir / f\"{stem}_S1_{DATE_TO_DOWNLOAD}.tif\")\n",
    "        else:\n",
    "            logging.warning(f\" No S1 for {stem}\")\n",
    "\n",
    "        s2_img, s2_reg = get_best_s2(pt, start, end)\n",
    "        if s2_img:\n",
    "            save_jpg(s2_img, s2_reg, tile_dir / f\"{stem}_S2_{DATE_TO_DOWNLOAD}.jpg\", VIS_PARAMS_S2)\n",
    "            save_tif(s2_img, s2_reg, tile_dir / f\"{stem}_S2_{DATE_TO_DOWNLOAD}.tif\",\n",
    "                     bands=['B4', 'B3', 'B2'])\n",
    "        else:\n",
    "            logging.warning(f\" No S2 for {stem}\")\n",
    "\n",
    "        with rasterio.open(lidar_fp) as src:\n",
    "            arr = src.read(1).astype(\"float32\")\n",
    "            nod = src.nodata\n",
    "            if nod is not None:\n",
    "                arr[arr == nod] = np.nan\n",
    "        hs1 = hillshade(arr, AZ1, ALT1)\n",
    "        hs2 = hillshade(arr, AZ2, ALT2)\n",
    "        comp = np.concatenate([hs1, hs2], axis=1)\n",
    "        Image.fromarray(comp).save(tile_dir / f\"{stem}_lidar_hillshade.jpg\", quality=90)\n",
    "\n",
    "    logging.info(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Archaeo-Pipeline)",
   "language": "python",
   "name": "archaeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
