{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import base64\n",
    "import textwrap\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ─────────────────────────── Load environment and config ───────────────────────────\n",
    "load_dotenv()\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Directory where predicted tile folders live\n",
    "PREDICTED_DIR = Path(config[\"results_dir\"]) / os.getenv(\"PREDICTED_SUBDIR\", \"predicted\")\n",
    "# Date string for Earth observation imagery\n",
    "DATE_TO_DOWNLOAD = os.getenv(\"GE_DATE\", \"2025-05-01\")\n",
    "\n",
    "# OpenAI credentials and model configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "VISION_MODEL   = os.getenv(\"VISION_MODEL\", \"gpt-4.1\")\n",
    "\n",
    "# Strip whitespace from the key and debug-print to verify\n",
    "if OPENAI_API_KEY:\n",
    "    OPENAI_API_KEY = OPENAI_API_KEY.strip()\n",
    "else:\n",
    "    raise RuntimeError(\"OPENAI_API_KEY is not set or empty in the environment\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ───────────────────────── Helper functions ─────────────────────────\n",
    "def compute_hillshade(dtm: np.ndarray, azimuth: float, altitude: float) -> np.ndarray:\n",
    "    az = np.deg2rad(azimuth)\n",
    "    alt = np.deg2rad(altitude)\n",
    "    dy, dx = np.gradient(dtm.astype(\"float32\"))\n",
    "    slope  = np.arctan(np.hypot(dx, dy))\n",
    "    aspect = np.arctan2(dy, -dx)\n",
    "    hs = (np.sin(alt) * np.cos(slope) +\n",
    "          np.cos(alt) * np.sin(slope) * np.cos(az - aspect))\n",
    "    return (np.clip(hs, 0, 1) * 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "def visualize_lidar_triptych(tif_path: Path, title: str = \"\"):\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        arr = src.read(1).astype(\"float32\")\n",
    "        nod = src.nodata\n",
    "        if nod is not None:\n",
    "            arr[arr == nod] = np.nan\n",
    "\n",
    "    hs1 = compute_hillshade(arr, azimuth=315, altitude=45)\n",
    "    hs2 = compute_hillshade(arr, azimuth=45,  altitude=30)\n",
    "    dy, dx = np.gradient(hs1.astype(\"float32\"))\n",
    "    edges = (np.hypot(dx, dy) >= 20).astype(\"uint8\") * 255\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4), constrained_layout=True)\n",
    "    axes[0].imshow(hs1, cmap=\"gray\", origin=\"upper\")\n",
    "    axes[0].set_title(f\"{title}\\nHS 315°/45°\", fontsize=10)\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(hs2, cmap=\"gray\", origin=\"upper\")\n",
    "    axes[1].set_title(\"HS 45°/30°\", fontsize=10)\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(edges, cmap=\"gray\", origin=\"upper\")\n",
    "    axes[2].set_title(\"Edges\", fontsize=10)\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def visualize_image(path: Path, title: str = None):\n",
    "    img = Image.open(path)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def describe_triplet_with_vision(paths, prompt_text):\n",
    "    messages = [{\"type\": \"text\", \"text\": prompt_text}]\n",
    "    for p in paths:\n",
    "        with open(p, \"rb\") as f:\n",
    "            b64 = base64.b64encode(f.read()).decode()\n",
    "        messages.append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/jpg;base64,{b64}\"}\n",
    "        })\n",
    "    resp = client.chat.completions.create(\n",
    "        model=VISION_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": messages}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "COMBINED_PROMPT = textwrap.dedent(f\"\"\"\n",
    "You are an expert in verifying archaeological features via remote sensing. Below are three co-registered images of the same area (date: {DATE_TO_DOWNLOAD}):\n",
    "\n",
    "1) LiDAR hillshade composite (two sun angles + edge gradient)\n",
    "2) Sentinel-1 SAR (VV)\n",
    "3) Sentinel-2 true-color\n",
    "\n",
    "Previously an ML model flagged this tile as an archaeological site. Your task is to verify **only what is visible**, without speculation.\n",
    "\n",
    "Answer format:\n",
    "[YES] if you clearly see a man-made earth structure (enclosure, mound, ditch, geoglyph) that:\n",
    " • has closed or linear geometry,\n",
    " • appears at leat in two images,\n",
    " • cannot be explained by roads, fields or natural erosion.\n",
    "\n",
    "[NO] otherwise.\n",
    "\n",
    "After the tag, include:\n",
    "1) **Observation**: describe 1–2 concrete patterns seen in each image.\n",
    "2) **Reasoning**: explain why these features exclude modern/natural causes.\n",
    "3) **Uncertainty**: if any image is too noisy, note \"Uncertain on [S1/S2] due to …\" and default to NO.\n",
    "\n",
    "If you lack direct access to the image, state this fact instead of guessing.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "results = []\n",
    "for tile_dir in sorted(PREDICTED_DIR.iterdir()):\n",
    "    if not tile_dir.is_dir():\n",
    "        continue\n",
    "    name = tile_dir.name\n",
    "\n",
    "    print(f\"\\n--- Contents of folder {name} ---\")\n",
    "    for f in sorted(tile_dir.iterdir()):\n",
    "        print(\"   \", f.name)\n",
    "\n",
    "    lidar_tif = tile_dir / f\"{name}_lidar.tif\"\n",
    "    lidar_jpg = tile_dir / f\"{name}_lidar_hillshade_contrast.jpg\"\n",
    "    if not lidar_jpg.exists():\n",
    "        lidar_jpg = tile_dir / f\"{name}_lidar_hillshade.jpg\"\n",
    "\n",
    "    p_s1 = tile_dir / f\"{name}_S1_{DATE_TO_DOWNLOAD}.jpg\"\n",
    "    p_s2 = tile_dir / f\"{name}_S2_{DATE_TO_DOWNLOAD}.jpg\"\n",
    "\n",
    "    rec = {\"tile\": name}\n",
    "    if lidar_tif.exists() and lidar_jpg.exists() and p_s1.exists() and p_s2.exists():\n",
    "        visualize_lidar_triptych(lidar_tif, title=name)\n",
    "        visualize_image(p_s1, f\"{name} — Sentinel-1\")\n",
    "        visualize_image(p_s2, f\"{name} — Sentinel-2\")\n",
    "\n",
    "        rec[\"vision_verification\"] = describe_triplet_with_vision(\n",
    "            [lidar_jpg, p_s1, p_s2],\n",
    "            COMBINED_PROMPT\n",
    "        )\n",
    "    else:\n",
    "        rec[\"vision_verification\"] = \"MISSING_IMAGE\"\n",
    "\n",
    "    print(f\"[{name}] -> {rec['vision_verification']}\")\n",
    "    results.append(rec)\n",
    "\n",
    "out_csv = PREDICTED_DIR / \"vision_verification.csv\"\n",
    "# Remove existing file to ensure it's overwritten each run\n",
    "if out_csv.exists():\n",
    "    out_csv.unlink()\n",
    "with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"tile\", \"vision_verification\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Done! Results saved to: {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Archaeo-Pipeline)",
   "language": "python",
   "name": "archaeo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
